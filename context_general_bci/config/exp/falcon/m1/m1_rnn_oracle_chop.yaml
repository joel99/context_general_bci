# @package _global_

defaults:
  - /model: rnn
  - /dataset: base
model:
  task:
    decode_normalizer: './data/zscore_m1_16d.pt'
dataset:
  max_length_ms: 4000
  max_tokens: 8192 
  explicit_alias_to_session: true

  neurons_per_token: 32
  max_channels: 64
  max_arrays: 1

  data_keys:
  - DataKey.spikes
  - DataKey.bhvr_vel
  - DataKey.bhvr_mask
  behavior_dim: 16
  scale_ratio: 1.0
  falcon_m1:
    respect_trial_boundaries: False
    chop_size_ms: 4000
  augmentations: ['explicit_crop_time']
  datasets:
  # Held-in models
  - falcon_FALCONM1-sub-MonkeyL-held-in-calib_ses-20120924.*
  - falcon_FALCONM1-sub-MonkeyL-held-in-calib_ses-20120926.*
  - falcon_FALCONM1-sub-MonkeyL-held-in-calib_ses-20120927.*
  - falcon_FALCONM1-sub-MonkeyL-held-in-calib_ses-20120928.*
  - falcon_FALCONM1-L_20121004_held_out_oracle
  - falcon_FALCONM1-L_20121017_held_out_oracle
  - falcon_FALCONM1-L_20121024_held_out_oracle
  eval_ratio: 0.0
train:
  max_batch_size: 32
  batch_size: 16 # reduced 4x
  early_stop_metric: val_kinematic_r2
  autoscale_batch_size: true
  patience: 250

fragment_datasets: True
effective_bsz: 32 # reduced 4x
sweep_cfg: 'rnn_basic'
sweep_mode: 'grid'