# @package _global_

# Extremely limited basic test for CER signs of life.
# JY is not implementing H2 thoroughly in NDT2 due to NaN instability with shuffle infill
# And general interest in broader pretraining framework, and lack of flashattn meaning only tiny models can be tested
# Note this smoketest is causal, as NDT3 is causal; several offline frameworks report sentence-acausal CER, because that is how speech BCIs are used.

defaults:
  - /model: flat_enc_dec
  - /model/task:
    - joint_bhvr_decode_flat
  - /dataset: flat
model:
  lr_ramp_steps: 50
  lr_decay_steps: 1500
  lr_interval: epoch
  causal: true
  neurons_per_token: 64
  session_embed_strategy: EmbedStrat.none
  transformer:
    max_trial_length: 6000 # 60 seconds... absurd
    # max_trial_length: 3000 # 60 seconds... absurd
    n_layers: 2
  decoder_layers: 1
  task:
    mask_ratio: 0.25 # for efficiency
    task_weights: [1.0, 0.005]
    decode_time_pool: 'mean'
    decode_normalizer: ''
    # tasks: [ModelTask.shuffle_infill] # , ModelTask.seq_decoding] # No joint task
    tasks: [ModelTask.shuffle_infill] # , ModelTask.seq_decoding] # No joint task
    # tasks: [ModelTask.shuffle_infill, ModelTask.seq_decoding] # No joint task
    metrics: []
    # metrics: [Metric.cer]
  decoder_context_integration: 'cross_attn'
  dropout: 0.2
dataset:
  pad_value: 2 # ! necessary poor workaround. 1. we need nonzero timestep to avoid nan-ing out in backbone for shuffle. 2. we don't have any timestep 0s in natural seq, only timestep 1 (for unknown reason), so timestep 2 needed for causal. can't go higher since we only have 3 spatial tokens too...
  # bin_size_ms: 40
  bin_size_ms: 20
  # max length in FALCONH2 is 4695 timesteps -> 14K tokens, 94 seconds
  max_length_ms: 108000 # 6000 timesteps, 3 tokens per -> 16200 tokens
  # max_length_ms: 60000 # 60000 / 20 = 3000
  max_tokens: 16384
  explicit_alias_to_session: true

  neurons_per_token: 64
  max_channels: 192
  max_arrays: 1

  data_keys:
  - DataKey.spikes
  - DataKey.bhvr_vel
  - DataKey.bhvr_mask
  datasets:
  - falcon_FALCONH2.*
  behavior_dim: 1
  behavior_classes: 32 # 31 + 1

train:
  max_batch_size: 256
  batch_size: 1
  autoscale_batch_size: true
  accumulate_batches: 1
  patience: 250
  early_stop_metric: val_loss

# sweep_cfg: simple_scratch
# sweep_mode: 'grid'