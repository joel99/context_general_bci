# @package _global_

tag: maze_stitch_large_ft

defaults:
  - /model: finetune
  - /model/task: nlb
  - /dataset: maze_nlb
  - /train: nlb
dataset:
  datasets:
  - mc_maze_large
  # - mc_maze.*
  nlb_maze:
    heldout_neurons: 40
  data_keys:
  - DataKey.spikes
  - DataKey.heldout_spikes
model:
  accelerate_new_params: 10.0

  readin_strategy: EmbedStrat.unique_project
  readout_strategy: EmbedStrat.unique_project
  readin_compress: False
  readin_dim: 128
  readout_dim: 128
  dropout: 0.4
  transformer:
    dropout: 0.4
    n_heads: 2
  task:
    tasks:
    # - ModelTask.infill
    - ModelTask.heldout_decoding
    metrics:
    # - Metric.bps
    - Metric.co_bps
    - Metric.block_co_bps
init_from_id: "maze_nlb_stitch_out-27qvb0yx"
# Needs accomodation for tiny batches
train:
  batch_size: 32