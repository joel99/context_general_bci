# @package _global_
# TODO think about LR
defaults:
  - /model:
    - pretrain_small
    # - accel_tune
  - /model/task:
    - bhvr_decode
  - /train: small
  - /dataset: base
model:
  # neurons_per_token: 8

  lr_init: 5e-5
  lr_ramp_steps: 1000
  lr_decay_steps: 10000
  accelerate_new_params: 10.0

  dropout: 0.1
dataset:
  max_length_ms: 2000 # fit
  max_arrays: 1

  # neurons_per_token: 8
  max_channels: 104

  bin_size_ms: 20
  data_keys:
  - DataKey.spikes
  - DataKey.bhvr_vel

  datasets:
  - odoherty_rtt-Indy-20161005_06
  # - odoherty_rtt-Indy-20161014_04
  eval_datasets:
  - odoherty_rtt-Indy-20161005_06
  odoherty_rtt:
    arrays:
    - Indy-M1
    - Loco-M1

init_from_id: rtt_indy_single-sweep-lr_and_dropout-t7avw2xi
init_tag: val_loss

# sweep_cfg: ft_reg
# sweep_trials: 8