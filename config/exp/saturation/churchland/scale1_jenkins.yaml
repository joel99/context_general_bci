# @package _global_
# We would like to assess whether maze reaching - presumably simpler than RTT - has different scaling properties.
defaults:
  - /model: flat_enc_dec
  - /dataset: flat
model:
  subject_embed_strategy: EmbedStrat.token
  array_embed_strategy: EmbedStrat.none
  task:
    mask_ratio: 0.5 # 0.25 is quite costly, but we want to see long tail of improvements, so go over 0.8
  neurons_per_token: 4
dataset:
  max_tokens: 4096 # fit
  max_length_ms: 2000 # fit
  max_arrays: 1
  scale_ratio: 1.0

  neurons_per_token: 4

  max_channels: 96
  bin_size_ms: 20
  datasets:
  - churchland_maze_jenkins.*
  eval_datasets:
  - churchland_maze_jenkins-0
  churchland_maze:
    arrays: ['Jenkins-M1', 'Nitschke-M1']