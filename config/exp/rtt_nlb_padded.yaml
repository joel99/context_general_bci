# @package _global_
tag: rtt_nlb

model:
  task:
    task: ModelTask.infill
  readin_strategy: EmbedStrat.token
  lr_schedule: 'cosine_warmup'
  lr_init: 5e-4
dataset:
  bin_size_ms: 5
  datasets:
  - mc_rtt
  max_channels: 98
  max_arrays: 1
train:
  steps: 10000
  batch_size: 128 # batch size reduced here since there's only ~1K trials
  patience: 50 # smaller batches
  # batch_size: 512
