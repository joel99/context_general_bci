# @package _global_
# Gunning for O'Doherty 0.57 R^2 with only 180 trials in day.

# Indy causal doesn't train decode, let's train another pretrained model on A100s
# From what we learned, factor 32 has almost no tradeoff with factor 4
defaults:
  - /model: flat_enc_dec
  - /dataset: flat
model:
  hidden_size: 384
  session_embed_token_count: 8
  subject_embed_strategy: EmbedStrat.none
  causal: true
  task:
    mask_ratio: 0.25 # higher mask ratios for iteration
  neurons_per_token: 16
dataset:
  neurons_per_token: 16
  max_tokens: 8192 # fit - est f4 = 3500 tokens per trial
  max_length_ms: 2000 # fit
  max_arrays: 1
  max_channels: 288 # (RTT)

  datasets:
  - odoherty_rtt.*
  eval_datasets:
  - odoherty_rtt-Indy-20161005_06