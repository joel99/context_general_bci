# @package _global_
# Gunning for O'Doherty 0.57 R^2 with only 180 trials in day.
defaults:
  - /model: flat_enc_dec
  - /dataset: flat
model:
  hidden_size: 384
  transformer:
    n_layers: 8
  subject_embed_strategy: EmbedStrat.token
  causal: true
  task:
    mask_ratio: 0.75 # higher mask ratios for iteration
  neurons_per_token: 4
dataset:
  neurons_per_token: 4
  max_tokens: 8192 # fit - est f4 = 3500 tokens per trial
  max_length_ms: 2000 # fit
  max_arrays: 1
  max_channels: 280 # (RTT)

  datasets:
  - odoherty_rtt-Indy.*
  - odoherty_rtt-Loco.*
  eval_datasets:
  - odoherty_rtt-Indy-20161005_06
train:
  batch_size: 4
