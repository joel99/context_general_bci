# @package _global_

tag: maze_nlb_feat

defaults:
  - /model:
    - finetune
  - /model/task: nlb
  - /dataset: maze_nlb
  - /train: nlb
model:
  dropout: 0.5
  hidden_size: 128
  session_embed_size: 128
  transformer:
    n_state: 128
    dropout: 0.5
  task:
    mask_ratio: 0.25
    freeze_backbone: True
  lr_init: 1e-3
  lr_ramp_steps: 5000
dataset:
  max_arrays: 1
train:
  patience: 1000

init_from_id: "maze_nlb_padded-1yy0yiuq"
