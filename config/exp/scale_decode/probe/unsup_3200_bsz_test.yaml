# @package _global_
defaults:
  - _default

dataset:
  datasets:
  - odoherty_rtt-Indy-20160627_01
  eval_datasets:
  - odoherty_rtt-Indy-20160627_01
  scale_limit_per_eval_session: 3190

model:
  task:
    blacklist_session_supervision:
    - odoherty_rtt-Indy-20160407_02
    - odoherty_rtt-Indy-20160627_01
    - odoherty_rtt-Indy-20170131_02

train:
  batch_size: 512
fragment_datasets: false

notes: "post hoc we observe data loading speed cancels out larger bsz, we need in mem data loader to exploit large scale tuning"