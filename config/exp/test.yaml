# @package _global_
tag: maze_med

defaults:
  - /model: pretrain_small
  - /dataset: maze_nlb
  - /train: nlb
model:
  readin_strategy: EmbedStrat.token
dataset:
  datasets:
  - mc_maze_medium
  max_channels: 137
train:
  epochs: 5000
  batch_size: 128
  patience: 500 # batches are smaller