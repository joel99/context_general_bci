# @package _global_
tag: maze_all_256

defaults:
  - /model: pretrain
  - /dataset: maze
  - /train: pretrain

model:
  subject_embed_strategy: EmbedStrat.token
  array_embed_strategy: EmbedStrat.token_add
  transformer:
    n_state: 256
  hidden_size: 256
  session_embed_size: 256
  subject_embed_size: 256
  array_embed_size: 256
  dropout: 0.2
train:
  patience: 300
  batch_size: 256