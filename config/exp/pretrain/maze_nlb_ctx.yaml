# @package _global_

tag: maze_nlb_ctx

defaults:
  - /model: pretrain_small
  - /dataset: maze_nlb
  - /train: nlb
dataset:
  datasets:
  - mc_maze.*
  # nlb_maze:
    # heldout_neurons: 40
  eval_datasets:
  - mc_maze_medium
  data_keys:
  - DataKey.spikes
  # - DataKey.heldout_spikes
model:
  session_embed_strategy: EmbedStrat.token
  subject_embed_strategy: EmbedStrat.none
  array_embed_strategy: EmbedStrat.none
  readin_strategy: EmbedStrat.contextual_mlp
  readout_strategy: EmbedStrat.contextual_mlp
  readin_compress: False
  readin_dim: 128
  readout_dim: 128
  dropout: 0.4
  transformer:
    dropout: 0.4
    n_heads: 2
  task:
    tasks:
    - ModelTask.infill
    # - ModelTask.heldout_decoding
    metrics:
    - Metric.bps
    # - Metric.co_bps
    # - Metric.block_co_bps
