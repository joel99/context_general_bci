# @package _global_
tag: maze_all_m6

defaults:
  - /model: pretrain
  - /dataset: maze
  - /train: pretrain

model:
  subject_embed_strategy: EmbedStrat.token
  array_embed_strategy: EmbedStrat.token_add
  task:
    mask_ratio: 0.6
# train:
  # patience: 300
# load_from_id: "maze_all-22wt8z8p"